Сьогодні закінчимо аналіз алгоритмів, зокрема асимптотичний. У другій частині почнемо розглядати перші структури.

Минулого разу розглянули загальну інформацію про алгоритми, різницю між ними. Під один підхід існує кілька алгоритмів.

Трудомісткість алгоритму - спроба визначити скільки часу потребує алгоритм. Всі алгоритми можна розділити за видом трудомісткості на такі:
- кількісно-залежні
- параметрично-залежні
- кількісно-параметричні

Трудомісткість не дуже зручна на практиці. Аби оцінити трудомісткість потрібно порахувати всі параметри з формули. Себто чим більше випадків якихось, тим більше дій потрібно виконати для прорахунку.

Аналіз алгоритму це допоміжний підготовчий етап, який не має займати більше часу ніж застосування алгоритму.

Найбільш розповсюджений і мабуть зручний спосіб аналізу це асимптотичний аналіз. Тут ми не фіксуємося на якихось конкретних числах, а радше дивимось як зростає час виконання зі зростанням кількості вхідних даних.
> Це я додумав, але припускаю шо це стосується саме цього

Сутність цього аналізу - не отримання числа. Він дозволяє зрозуміти як зміниться складність алгоритму при збільшенні розміру.
> Все ж я був правий.

За допомогою якоїсть функції типу `f=n` чи `f=n^2` чи `f=lg(n)`, тощо. Фактично ми дивимось як збільшується час виконання алгоритму зі збільшенням кількості вхідних даних. 

Окрім того, ми не витрачаємо час на конкретну кількість дій, просто використовуємо формулу. Нас цікавить сама природа функції - як вона зростає, як швидко. Про це і є асимптотичний аналіз.

У асимптотичного аналізу є 3 типи оцінок алгоритму

1. Θ - тета
Тут ми приблизно прораховуємо приблизну кількість дій, яка буде виконуватись. Маємо певну криву, яка дозволяє оцінити алгоритм. Сутність - починаючи зі значення N0 функція F(n) матиме значення, що не буде перевищувати значення F(G(N))xC2... Визначаємо коротше межі за які функція виходити не може. При чому зверху, і знизу. Висновок: за допомогою функції, за якою ми визначаємо складність алгоритми, за межі коефіцієнтів ми знаємо шо функція не вийде. 
> Поки шо не дуже розумію цей аналіз алгоритмів. Чимось дуже схоже на [[Big-O Notation]], але якісь тут ще межі є.

2. О - велика О
Оцінка О це оцінка, яка обмежується тільки згори, на відміну від тета, яка обмежує згори і знизу. При розрахунку оцінки О необхідно звести до найближчого значення. З велкою О завжди виникає клас функцій, до яких можна звести нашу. 
> Нічого не розумію абсолютно. 

Коротше якшо бачимо оцінку тета, можемо зрозуміти все більш точно. Якшо оцінка О, тут треба бути впевненим наскільки чітко вона була обрана. 

Маючи функцію `4n^2+3n-8` яка буде оцінка тета? Гадки не маю, але припускаю що n^2. Я був правий, але звичайно шо промовчав просто.

Тут дивимось коротше на найбільший ступінь у функції, і від нього виходимо. Коефіцієнти і меньші ступені не важливі.

Якшо функція `2n^3+4n^2+6n+9`, то оцінкою тета буде n^3. 

3. Ω - омега
Оцінка омега це обмеження знизу. Знову, коли немає обмежень з двох боків, також не має такої залежності. Так само як і з великою О, маємо цілий клас функцій, яка буде підходити під оцінку омега.

Зазвичай аналізуючи якийсь алгоритм, ми можемо бачити або тета (ніколи не бачив), або О.

Аналіз алгоритмів - це оцінка збільшення складності, себто часу виконання алгоритму, зі збільшенням вхідних даних. 

Найбільш розповсюджені конкретні функції оцінки алгоритмів:
- T(n) = 1 - [[constant]] time
- T(n) = log2 n - logarithmic time
- T(n) = n - linear time
- T(n) = n log2 n - almost linear time
- T(n) = n2 - quadratic time
- T(n) = n3 - cubic time

Розбір кожного з них
1. O(1)
Час виконання не залежить від вхідних даних. Зазвичай це якесь діставання елементу з масиву за індексом. Дуже обмежене використання, рідко зустрічається.
Приклади: accessing items in array, pushing and popping elements from array.

2. O(log(n))
Базується на розбиття задачі на підзадачі, які мають фіксований розмір. Початковий розмір впливає на те, скільки розбиттів робимо, на приклад. Але після розбиття виконуємо фіксовану кількість дій. Тобто розмір впливає, але тільки під час розбиття, ніде більше. 
Приклади: binary search, divide and conquer algorithms - FFT, merge sort, binary exponent

3. O(n)
Алгоритми лінійного часу. Працюємо з масивчиком, а саме з його елементами. Проходимо просто по всім елементам, тобто якшо в нас двомірний масив 4x5, то маємо 20 елементів. Важлива кількість загальна. Працюючи з кожним елементом використовуємо фіксований час. 
Приклади: linear search, counting for occurences of elements, finding maximum/minimum element

Лінійні структури даних (нарешті)

1. Одномірний масив - Array
Є певний набір елементів, розташованих один після одного у пам'яті. Кожен елемент має номер - називається індексом, індексація починається з нуля в нормальних мовах програмування. З нуля тому шо є базова адреса, з якої починається збереження адрес. Пошук і доступ до елементу є дуже швидким, O(1). Назва масиву зберігає адресу нульового елементу. 

2. Зв'язний список - List
Може бути або однонаправлений або двонаправлений. Елемент називається вузлом - Node. кожен вузол, окрім голови, містить дані, і покажчик на наступний. 

Розглянемо операції над списками:
- створення елементу
- додавання вузла в початок
- до